# -*- coding: utf-8 -*-
"""
FC2 æµå‡ºæ£€æµ‹å™¨ - ä¸»ç¨‹åº

æ­¤ç¨‹åºç”¨äºåˆ†æFC2è§†é¢‘ä¿¡æ¯ï¼Œå¯é€šè¿‡ä½œè€…IDæˆ–å¥³ä¼˜IDè¿›è¡Œåˆ†æï¼Œ
è·å–è§†é¢‘æµå‡ºçŠ¶æ€ã€ç£åŠ›é“¾æ¥å’Œç¼©ç•¥å›¾ç­‰ä¿¡æ¯ã€‚
"""
import argparse
import json
import os
import re
import ssl
import sys
import time
import traceback
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from json.decoder import JSONDecodeError
from urllib.error import HTTPError, URLError
import glob

from requests.exceptions import ConnectionError, RequestException, Timeout

from src.checkers.fc2analyzer import FC2Analyzer
from config import config
from src.utils.fc2_video_parser import find_writer_by_video
from src.utils.logger import get_logger
from src.utils.report_generator import ReportGenerator
from src.utils.ui_manager import RichUIManager
from src.writers.writer_extractor import WriterExtractor
from src.utils.i18n import get_text as _, switch_language, get_current_language, SUPPORTED_LANGUAGES
from src.utils.jellyfin_metadata_generator import JellyfinMetadataGenerator

# è·å–ä¸»ç¨‹åºæ—¥å¿—è®°å½•å™¨
logger = get_logger("main")

def print_usage():
    """æ‰“å°ä½¿ç”¨å¸®åŠ©ä¿¡æ¯"""
    # è·å–å½“å‰è¯­è¨€
    current_lang = get_current_language()
    
    # æ ¹æ®å½“å‰è¯­è¨€è®¾ç½®ç›®æ ‡è¯­è¨€
    if current_lang == "zh":
        target_lang = "en"
    elif current_lang == "en":
        target_lang = "ja"
    else:  # current_lang == "ja" or any other
        target_lang = "zh"
    
    usage = f"""
{_('usage_title', 'ä½¿ç”¨æ–¹æ³•')}: python run.py [é€‰é¡¹]

{_('usage_options', 'é€‰é¡¹')}:
  -h, --help                {_('usage_help', 'æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯')}
  -w ID, --writer ID        {_('usage_writer', 'åˆ†æä½œè€…IDçš„è§†é¢‘')}
  -a ID, --actress ID       {_('usage_actress', 'åˆ†æå¥³ä¼˜IDçš„è§†é¢‘')}
  -b IDs, --batch IDs       {_('usage_batch', 'æ‰¹é‡å¤„ç†å¤šä¸ªä½œè€…ID (ç”¨è‹±æ–‡é€—å·åˆ†éš”)')}
  -ba IDs, --batch-actress IDs  {_('usage_batch_actress', 'æ‰¹é‡å¤„ç†å¤šä¸ªå¥³ä¼˜ID (ç”¨è‹±æ–‡é€—å·åˆ†éš”)')}
  -v ID, --video ID         {_('usage_video', 'é€šè¿‡è§†é¢‘IDæŸ¥æ‰¾å¹¶åˆ†æä½œè€…')}
  -t NUM, --threads NUM     {_('usage_threads', 'æŒ‡å®šå¹¶è¡Œçº¿ç¨‹æ•° (é»˜è®¤30)')}
  --jellyfin                {_('usage_jellyfin', 'ç”ŸæˆJellyfinå…¼å®¹çš„å…ƒæ•°æ®ï¼›å¯å•ç‹¬ä½¿ç”¨ï¼Œä¼šæŸ¥æ‰¾48å°æ—¶å†…çš„åˆ†æç»“æœ')}
  --no-magnet               {_('usage_no_magnet', 'ä¸è·å–ç£åŠ›é“¾æ¥')}
  --no-image                {_('usage_no_image', 'ä¸ä¸‹è½½è§†é¢‘ç¼©ç•¥å›¾')}
  -l LANG, --lang LANG      {_('usage_lang', 'è®¾ç½®ç•Œé¢è¯­è¨€ (æ”¯æŒ: zh, en, ja)')}
  -c, --config              {_('usage_config', 'æ˜¾ç¤ºé…ç½®ä¿¡æ¯')}
  -s, --sites               {_('usage_sites', 'æ˜¾ç¤ºæ£€æŸ¥ç«™ç‚¹åˆ—è¡¨')}
  -e, --extract             {_('usage_extract', 'æå–çƒ­é—¨ä½œè€…åˆ—è¡¨')}
  --clear-cache             {_('usage_clear_cache', 'æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®')}

{_('usage_examples', 'ç¤ºä¾‹')}:
  python run.py -w 5656               # {_('example_writer', 'åˆ†æä½œè€…ID 5656 çš„è§†é¢‘')}
  python run.py -a 5711               # {_('example_actress', 'åˆ†æå¥³ä¼˜ID 5711 çš„è§†é¢‘')}
  python run.py -b 5656,3524,4461     # {_('example_batch', 'æ‰¹é‡å¤„ç†å¤šä¸ªä½œè€…')}
  python run.py -ba 5711,3986,4219    # {_('example_batch_actress', 'æ‰¹é‡å¤„ç†å¤šä¸ªå¥³ä¼˜')}
  python run.py -v 1248860            # {_('example_video', 'é€šè¿‡è§†é¢‘IDæŸ¥æ‰¾å¹¶åˆ†æä½œè€…')}
  python run.py -w 5656 -t 10         # {_('example_threads', 'ä½¿ç”¨10ä¸ªçº¿ç¨‹åˆ†æä½œè€…è§†é¢‘')}
  python run.py -w 5656 --jellyfin    # {_('example_jellyfin', 'åˆ†æä½œè€…è§†é¢‘å¹¶ç”ŸæˆJellyfinå…ƒæ•°æ®')}
  python run.py --jellyfin            # {_('example_jellyfin', 'ä½¿ç”¨æœ€è¿‘çš„åˆ†æç»“æœç”ŸæˆJellyfinå…ƒæ•°æ®')}
  python run.py -a 5711 --no-magnet   # {_('example_no_magnet', 'åˆ†æå¥³ä¼˜è§†é¢‘ä½†ä¸è·å–ç£åŠ›é“¾æ¥')}
  python run.py -w 5656 --no-image    # {_('example_no_image', 'åˆ†æä½œè€…è§†é¢‘ä½†ä¸ä¸‹è½½ç¼©ç•¥å›¾')}
  python run.py -l {target_lang}               # {_('example_lang', 'ä½¿ç”¨è‹±æ–‡ç•Œé¢')}
  python run.py -c                    # {_('example_config', 'æ˜¾ç¤ºé…ç½®ä¿¡æ¯')}
  python run.py -e                    # {_('example_extract', 'æå–çƒ­é—¨ä½œè€…åˆ—è¡¨')}
  python run.py --clear-cache         # {_('example_clear_cache', 'æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®')}


{_('advanced_usage', 'é«˜çº§ç”¨æ³•')}:
  # {_('advanced_example1', 'ä½¿ç”¨20ä¸ªçº¿ç¨‹åˆ†æä½œè€…è§†é¢‘ï¼Œç”ŸæˆJellyfinå…ƒæ•°æ®ï¼Œå¹¶ä½¿ç”¨è‹±æ–‡ç•Œé¢')}
  python run.py -w 5656 -t 20 --jellyfin -l en
  
  # {_('advanced_example2', 'æ‰¹é‡åˆ†æå¤šä¸ªä½œè€…ï¼Œä½¿ç”¨æœ€å¤§50ä¸ªçº¿ç¨‹ï¼Œä¸ä¸‹è½½ç¼©ç•¥å›¾ä½†è·å–ç£åŠ›é“¾æ¥ï¼Œå¹¶ç”ŸæˆJellyfinå…ƒæ•°æ®')}
  python run.py -b 5656,3524,4461,7890,6543,2109 -t 50 --no-image --jellyfin
"""
    print(usage)


def show_config_info():
    """æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯"""
    print(f"=== {_('config.config_info_title', 'å½“å‰é…ç½®ä¿¡æ¯')} ===")
    print(f"{_('config.config_data_dir', 'æ•°æ®ç›®å½•')}: {config.cache_dir}")
    print(f"{_('config.config_max_workers', 'æœ€å¤§çº¿ç¨‹æ•°')}: {config.max_workers}")
    print(f"{_('config.config_max_retries', 'æœ€å¤§é‡è¯•æ¬¡æ•°')}: {config.max_retries}")
    print(f"{_('config.config_cache_ttl', 'ç¼“å­˜æœ‰æ•ˆæœŸ')}: {config.cache_ttl/3600:.1f} {_('config.config_hours', 'å°æ—¶')}")
    print(f"{_('config.config_language', 'å½“å‰è¯­è¨€')}: {get_current_language()}")

    # æ˜¾ç¤ºæ£€æŸ¥ç«™ç‚¹é…ç½®
    show_check_sites()


def show_check_sites():
    """æ˜¾ç¤ºå½“å‰é…ç½®çš„æ£€æŸ¥ç«™ç‚¹"""
    check_sites = sorted(config.check_sites, key=lambda x: x["priority"])

    if not check_sites:
        print(f"âš ï¸ {_('sites_none', 'æœªé…ç½®ä»»ä½•æ£€æŸ¥ç«™ç‚¹ï¼Œå°†ä½¿ç”¨é»˜è®¤ç«™ç‚¹')}")
        return

    print(f"\n=== {_('sites_title', 'è§†é¢‘æ£€æŸ¥ç«™ç‚¹ (æŒ‰ä¼˜å…ˆçº§æ’åº)')} ===")
    for idx, site in enumerate(check_sites, 1):
        site_name = site.get("name", site["url"].split("/")[2])
        print(f"{idx}. {_('sites_name', 'ç«™ç‚¹')}: {site_name}")
        print(f"   {_('sites_url', 'ç½‘å€æ¨¡æ¿')}: {site['url']}")
        print(f"   {_('sites_priority', 'ä¼˜å…ˆçº§')}: {site['priority']}")


def extract_writer_info():
    """æå–çƒ­é—¨ä½œè€…åˆ—è¡¨

    ä»FC2PPVDBè·å–çƒ­é—¨ä½œè€…åˆ—è¡¨å¹¶ä¿å­˜åˆ°æ–‡ä»¶

    è¿”å›:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    extractor = WriterExtractor()

    print(_("extract_writers.start", "å¼€å§‹è·å–çƒ­é—¨ä½œè€…åˆ—è¡¨..."))
    writer_data = extractor.extract_all_writers()
    if writer_data:
        print(f"âœ… {_('extract_writers.success', 'å·²è·å– {count} ä¸ªçƒ­é—¨ä½œè€…ä¿¡æ¯').format(count=len(writer_data))}")
        return True
    else:
        print(f"âŒ {_('extract_writers.failure', 'æ— æ³•è·å–çƒ­é—¨ä½œè€…åˆ—è¡¨')}")
        return False


def is_leaked(result):
    """
    åˆ¤æ–­è§†é¢‘æ˜¯å¦å·²æ³„éœ²
    
    å‚æ•°:
        result: è§†é¢‘ç»“æœå¯¹è±¡
        
    è¿”å›:
        bool: æ˜¯å¦å·²æ³„éœ²
    """
    # å¦‚æœleakedå­—æ®µå­˜åœ¨å¹¶ä¸”ä¸ºTrueï¼Œç›´æ¥è¿”å›True
    if result.get("leaked") is True:
        return True
    
    status = result.get("status")
    
    # å¦‚æœstatusæ˜¯availableï¼Œåˆ™è§†ä¸ºå·²æ³„éœ²
    if status == "available":
        return True
        
    # å¦‚æœstatusæ˜¯å¸ƒå°”ç±»å‹
    if isinstance(status, bool):
        return status
        
    # å¦‚æœstatusæ˜¯å­—ç¬¦ä¸²ä¸”ä¸ºleakedã€yesæˆ–true
    if isinstance(status, str) and status.lower() in ["leaked", "yes", "true"]:
        return True
        
    # é»˜è®¤ä¸ºæœªæ³„éœ²
    return False


def check_videos(
    target_id, is_actress=False, threads=None, with_magnet=True, download_images=True, generate_jellyfin=False
):
    """é€šç”¨è§†é¢‘åˆ†æå‡½æ•°

    è·å–æŒ‡å®šIDçš„æ‰€æœ‰è§†é¢‘å¹¶æ£€æŸ¥å…¶æµå‡ºçŠ¶æ€ï¼ŒåŒæ—¶è·å–ç£åŠ›é“¾æ¥å’Œç¼©ç•¥å›¾

    å‚æ•°:
        target_id: ä½œè€…IDæˆ–å¥³ä¼˜ID
        is_actress: æ˜¯å¦ä¸ºå¥³ä¼˜ID
        threads: å¹¶è¡Œçº¿ç¨‹æ•°
        with_magnet: æ˜¯å¦è·å–ç£åŠ›é“¾æ¥
        download_images: æ˜¯å¦ä¸‹è½½ç¼©ç•¥å›¾
        generate_jellyfin: æ˜¯å¦ç”ŸæˆJellyfinå…ƒæ•°æ®

    è¿”å›:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    # æ ¹æ®ç±»å‹ç¡®å®šæ˜¾ç¤ºæ–‡æœ¬
    entity_type = _("check_videos.entity_type_actress", "å¥³ä¼˜") if is_actress else _("check_videos.entity_type_writer", "ä½œè€…")

    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = FC2Analyzer(
            target_id,
            is_actress=is_actress,
            with_magnet=with_magnet,
            download_images=download_images,
            quiet_mode=False,
        )

        # è®¾ç½®å¹¶è¡Œçº¿ç¨‹æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®ï¼Œæœ€åæ˜¯é»˜è®¤å€¼
        max_workers = threads if threads is not None else config.max_workers
        # ç¡®ä¿çº¿ç¨‹æ•°åœ¨åˆç†èŒƒå›´å†…
        max_workers = max(1, min(max_workers, 50))  # è‡³å°‘1ä¸ªçº¿ç¨‹ï¼Œæœ€å¤š50ä¸ªçº¿ç¨‹

        # è®¾ç½®è¯·æ±‚è¶…æ—¶
        timeout = config.timeout  # ä»é…ç½®è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤15ç§’

        # è·å–åç§°
        try:
            author_name = analyzer.fetch_author_name()
            if author_name:
                print(f"âœ… {_('check_videos.author_name_success', '{entity_type}åç§°: {name}').format(entity_type=entity_type, name=author_name)}")
        except ConnectionError as e:
            logger.error(f"è·å–{entity_type}åç§°æ—¶è¿æ¥é”™è¯¯: {e}")
            print(f"âš ï¸ {_('check_videos.author_name_error_connection', 'è·å–{entity_type}åç§°æ—¶è¿æ¥é”™è¯¯: {error}').format(entity_type=entity_type, error=e)}")
            author_name = None
        except Timeout as e:
            logger.error(f"è·å–{entity_type}åç§°æ—¶è¿æ¥è¶…æ—¶: {e}")
            print(f"âš ï¸ {_('check_videos.author_name_error_timeout', 'è·å–{entity_type}åç§°æ—¶è¿æ¥è¶…æ—¶: {error}').format(entity_type=entity_type, error=e)}")
            author_name = None
        except HTTPError as e:
            logger.error(f"è·å–{entity_type}åç§°æ—¶HTTPé”™è¯¯: {e.code} - {e.reason}")
            print(f"âš ï¸ {_('check_videos.author_name_error_http', 'è·å–{entity_type}åç§°æ—¶HTTPé”™è¯¯: {code} - {reason}').format(entity_type=entity_type, code=e.code, reason=e.reason)}")
            author_name = None

        # è·å–è§†é¢‘åˆ—è¡¨
        try:
            videos = analyzer.fetch_video_ids()
            if not videos:
                logger.warning(f"æœªæ‰¾åˆ°{entity_type} {target_id} çš„è§†é¢‘")
                print(f"âŒ {_('check_videos.videos_not_found', 'æœªæ‰¾åˆ°{entity_type} {id} çš„è§†é¢‘').format(entity_type=entity_type, id=target_id)}")
                return False
        except ConnectionError as e:
            logger.error(f"è·å–è§†é¢‘åˆ—è¡¨æ—¶è¿æ¥é”™è¯¯: {e}")
            print(f"âŒ {_('check_videos.videos_error_connection', 'è·å–è§†é¢‘åˆ—è¡¨æ—¶è¿æ¥é”™è¯¯: {error}').format(error=e)}")
            return False
        except Timeout as e:
            logger.error(f"è·å–è§†é¢‘åˆ—è¡¨æ—¶è¿æ¥è¶…æ—¶: {e}")
            print(f"âŒ {_('check_videos.videos_error_timeout', 'è·å–è§†é¢‘åˆ—è¡¨æ—¶è¿æ¥è¶…æ—¶: {error}').format(error=e)}")
            return False
        except HTTPError as e:
            logger.error(f"è·å–è§†é¢‘åˆ—è¡¨æ—¶HTTPé”™è¯¯: {e.code} - {e.reason}")
            print(f"âŒ {_('check_videos.videos_error_http', 'è·å–è§†é¢‘åˆ—è¡¨æ—¶HTTPé”™è¯¯: {code} - {reason}').format(code=e.code, reason=e.reason)}")
            return False
        except JSONDecodeError as e:
            logger.error(f"è§£æè§†é¢‘æ•°æ®æ—¶æ ¼å¼é”™è¯¯: {e}")
            print(f"âŒ {_('check_videos.videos_error_json', 'è§£æè§†é¢‘æ•°æ®æ—¶æ ¼å¼é”™è¯¯: {error}').format(error=e)}")
            return False

        # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
        total_videos = len(videos)
        print(_("check_videos.videos_found", "æ€»å…±æ‰¾åˆ° {count} ä¸ªè§†é¢‘ï¼Œå¼€å§‹åˆ†æ...").format(count=total_videos))

        # åˆ†æè§†é¢‘æ—¶æ˜ç¡®æŒ‡å®šçº¿ç¨‹æ•°å’Œè¶…æ—¶è®¾ç½®
        try:
            # æ³¨æ„ï¼šanalyze_videosæ–¹æ³•ä¸æ¥å—max_workerså‚æ•°
            # çº¿ç¨‹æ•°ç”±FC2Analyzeræ„é€ å‡½æ•°æˆ–å†…éƒ¨é…ç½®æ§åˆ¶
            results, stats = analyzer.analyze_videos(videos)
        except Exception as e:
            logger.error(f"åˆ†æè§†é¢‘æ—¶å‡ºé”™: {type(e).__name__}: {e}")
            print(f"âŒ {_('check_videos.analyze_error', 'åˆ†æè§†é¢‘æ—¶å‡ºé”™: {error}').format(error=e)}")
            return False

        # ä¿å­˜åˆ†æç»“æœ
        try:
            analyzer.save_results()
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†æç»“æœæ—¶å‡ºé”™: {type(e).__name__}: {e}")
            print(f"âŒ ä¿å­˜åˆ†æç»“æœæ—¶å‡ºé”™: {e}")

        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            try:
                os.makedirs(config.result_dir, exist_ok=True)
            except PermissionError as e:
                logger.error(f"åˆ›å»ºç»“æœç›®å½•æ—¶æƒé™ä¸è¶³: {e}")
                print(f"âŒ {_('check_videos.dir_error_permission', 'åˆ›å»ºç»“æœç›®å½•æ—¶æƒé™ä¸è¶³: {error}').format(error=e)}")
                return False
            except OSError as e:
                logger.error(f"åˆ›å»ºç»“æœç›®å½•æ—¶ç³»ç»Ÿé”™è¯¯: {e}")
                print(f"âŒ {_('check_videos.dir_error_system', 'åˆ›å»ºç»“æœç›®å½•æ—¶ç³»ç»Ÿé”™è¯¯: {error}').format(error=e)}")
                return False

            # ç”Ÿæˆè‡ªå®šä¹‰çš„ä¿å­˜è·¯å¾„
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # æ£€æŸ¥åç§°æ˜¯å¦åŒ…å«éæ³•å­—ç¬¦
            has_special_chars = False
            if author_name:
                has_special_chars = any(
                    c in author_name
                    for c in ["\\", "/", "*", "?", ":", '"', "<", ">", "|"]
                )

            if has_special_chars or not author_name:
                # å¦‚æœåŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–åç§°ä¸ºç©ºï¼Œåªä½¿ç”¨ID
                print(f"âš ï¸ {_('check_videos.name_special_chars', '{entity_type}åç§°åŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–ä¸ºç©ºï¼Œä»…ä½¿ç”¨IDä½œä¸ºæ–‡ä»¶å').format(entity_type=entity_type)}")
                save_path = os.path.join(
                    config.result_dir,
                    f"{target_id}_{timestamp}.txt",
                )
            else:
                # æ¸…ç†åç§°ï¼Œç¡®ä¿å®‰å…¨
                cleaned_name = re.sub(r'[\\/*?:"<>|]', "_", author_name).strip()
                save_path = os.path.join(
                    config.result_dir,
                    f"{target_id}_{cleaned_name}_{timestamp}.txt",
                )

            # æ‰“å°åŸºæœ¬çš„ç»Ÿè®¡ä¿¡æ¯
            total = len(results)
            leaked = sum(1 for r in results if is_leaked(r))
            leak_ratio = (leaked / total) * 100 if total > 0 else 0

            # å†™å…¥ç»“æœæ‘˜è¦
            try:
                with open(save_path, "w", encoding="utf-8") as f:
                    f.write(
                        f"{entity_type}: {target_id} [{author_name or 'Unknown'}]\n"
                    )
                    f.write(f"æ€»è§†é¢‘æ•°: {total}\n")
                    f.write(f"å·²æµå‡ºæ•°: {leaked}\n")
                    f.write(f"æµå‡ºæ¯”ä¾‹: {leak_ratio:.2f}%\n\n")

                    # å†™å…¥åŸºæœ¬çš„è§†é¢‘ä¿¡æ¯
                    f.write("è§†é¢‘åˆ—è¡¨:\n")
                    for r in results:
                        video_id = r.get("video_id", r.get("id", "unknown"))
                        status = "å·²æµå‡º" if is_leaked(r) else "æœªæµå‡º"
                        title = r.get("title", f"FC2-PPV-{video_id}")

                        # æ·»åŠ ç£åŠ›é“¾æ¥ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                        magnet_info = ""
                        if with_magnet and r.get("has_magnet", False):
                            magnet_info = f" [æœ‰ç£é“¾]"

                        # æ·»åŠ å›¾ç‰‡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                        image_info = ""
                        if download_images and r.get("image_downloaded", False):
                            image_info = f" [æœ‰å›¾ç‰‡]"

                        f.write(
                            f"{video_id} - {status}{magnet_info}{image_info} - {title}\n"
                        )

                print(f"âœ… {_('check_videos.result_saved', 'ç»“æœå·²ä¿å­˜åˆ°: {path}').format(path=save_path)}")
            except PermissionError as e:
                logger.error(f"å†™å…¥ç»“æœæ–‡ä»¶æ—¶æƒé™ä¸è¶³: {e}")
                print(f"âŒ {_('check_videos.write_error_permission', 'å†™å…¥ç»“æœæ–‡ä»¶æ—¶æƒé™ä¸è¶³: {error}').format(error=e)}")
            except IOError as e:
                logger.error(f"å†™å…¥ç»“æœæ–‡ä»¶æ—¶I/Oé”™è¯¯: {e}")
                print(f"âŒ {_('check_videos.write_error_io', 'å†™å…¥ç»“æœæ–‡ä»¶æ—¶I/Oé”™è¯¯: {error}').format(error=e)}")

            # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            analyzer.display_results(results, stats)

            # è°ƒç”¨generate_reportsæ–¹æ³•ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
            try:
                reports = analyzer.generate_reports(target_id, results, author_name)
                if reports:
                    print(f"âœ… {_('check_videos.report_success', 'æˆåŠŸä¸º{entity_type} {id} ç”Ÿæˆ {count} ä¸ªåˆ†ç±»æŠ¥å‘Š').format(entity_type=entity_type, id=target_id, count=len(reports))}")
                    for report_type, report_path in reports.items():
                        print(f"  - {report_type}: {report_path}")
            except Exception as e:
                logger.error(f"ç”Ÿæˆåˆ†ç±»æŠ¥å‘Šæ—¶å‡ºé”™: {type(e).__name__}: {e}")
                print(f"âš ï¸ {_('check_videos.report_error', 'ç”Ÿæˆåˆ†ç±»æŠ¥å‘Šæ—¶å‡ºé”™: {error}').format(error=e)}")

        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœæ—¶å‡ºé”™: {type(e).__name__}: {e}\n{traceback.format_exc()}")
            print(f"âš ï¸ ä¿å­˜ç»“æœæ—¶å‡ºé”™: {e}")
            return False

        print(_("check_videos.total_videos", "æ€»è§†é¢‘æ•°: {count}").format(count=total))
        print(_("check_videos.leaked_videos", "å·²æµå‡ºæ•°: {count}").format(count=leaked))
        print(_("check_videos.leaked_ratio", "æµå‡ºæ¯”ä¾‹: {ratio}%").format(ratio=f"{leak_ratio:.2f}"))

        # åœ¨å‡½æ•°ç»“å°¾éƒ¨åˆ†æ·»åŠ Jellyfinå…ƒæ•°æ®ç”Ÿæˆä»£ç 
        if generate_jellyfin and results:
            try:
                print("\n=== Jellyfinå…ƒæ•°æ® ===")
                jellyfin_generator = JellyfinMetadataGenerator()
                
                # ä»è§†é¢‘ç»“æœä¸­æå–å·²æµå‡ºçš„è§†é¢‘
                leaked_videos = [v for v in results if v.get("status") in ["leaked", "available", "å·²æµå‡º"]]
                
                if not leaked_videos:
                    print("âŒ æ²¡æœ‰å·²æµå‡ºçš„è§†é¢‘ï¼Œè·³è¿‡ç”ŸæˆJellyfinå…ƒæ•°æ®")
                    return results
                
                # åˆ›å»ºä½œè€…ä¿¡æ¯å­—å…¸
                author_info = {
                    "id": target_id,
                    "name": author_name
                }
                
                # å¼‚æ­¥è°ƒç”¨æ‰¹é‡ç”Ÿæˆå…ƒæ•°æ®
                import asyncio
                # ä½¿ç”¨asyncio.runè¿è¡Œå¼‚æ­¥å‡½æ•°
                metadata_results = asyncio.run(jellyfin_generator.batch_generate_metadata(
                    leaked_videos,
                    author_info=author_info,
                    enrich_from_web=True  # å§‹ç»ˆä»ç½‘ç»œè·å–é¢å¤–ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡ç­¾
                ))
                
                if metadata_results:
                    print(f"âœ… æˆåŠŸç”Ÿæˆ {len(metadata_results)} ä¸ªJellyfinå…ƒæ•°æ®æ–‡ä»¶")
                else:
                    print("âŒ æœªç”Ÿæˆä»»ä½•Jellyfinå…ƒæ•°æ®æ–‡ä»¶")
                
            except Exception as e:
                print(f"âŒ ç”ŸæˆJellyfinå…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")

        return True
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­äº†æ“ä½œ")
        print("\nâš ï¸ æ“ä½œå·²ä¸­æ–­")
        return False
    except ssl.SSLError as e:
        logger.error(f"SSLè¿æ¥é”™è¯¯: {e}")
        print(f"âŒ SSLè¿æ¥é”™è¯¯: {e}")
        return False
    except Exception as e:
        logger.error(
            f"åˆ†æ{entity_type}è§†é¢‘æ—¶å‡ºé”™: {type(e).__name__}: {e}\n{traceback.format_exc()}"
        )
        print(f"âŒ åˆ†æ{entity_type}è§†é¢‘æ—¶å‡ºé”™: {type(e).__name__}: {e}")
        return False


def process_multiple_ids(
    ids, is_actress=False, threads=None, with_magnet=True, download_images=True, generate_jellyfin=False
):
    """æ‰¹é‡å¤„ç†å¤šä¸ªä½œè€…æˆ–å¥³ä¼˜

    ä¾æ¬¡åˆ†æå¤šä¸ªIDçš„è§†é¢‘ï¼Œå¹¶ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š

    å‚æ•°:
        ids: IDåˆ—è¡¨æˆ–é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
        is_actress: æ˜¯å¦ä¸ºå¥³ä¼˜ID
        threads: å¹¶è¡Œçº¿ç¨‹æ•°
        with_magnet: æ˜¯å¦è·å–ç£åŠ›é“¾æ¥
        download_images: æ˜¯å¦ä¸‹è½½ç¼©ç•¥å›¾
        generate_jellyfin: æ˜¯å¦ç”ŸæˆJellyfinå…ƒæ•°æ®

    è¿”å›:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    # ç¡®å®šå¤„ç†çš„å®ä½“ç±»å‹
    entity_type = "å¥³ä¼˜" if is_actress else "ä½œè€…"
    id_field = "actress_id" if is_actress else "writer_id"
    name_field = "actress_name" if is_actress else "writer_name"

    # è§£æID
    if isinstance(ids, str):
        id_list = ids.split(",")
    else:
        id_list = ids

    # å»é™¤ç©ºç™½é¡¹å’Œé‡å¤é¡¹
    id_list = [item.strip() for item in id_list if item.strip()]
    id_list = list(set(id_list))

    if not id_list:
        print(f"âŒ æœªæä¾›æœ‰æ•ˆçš„{entity_type}ID")
        return False

    # è®¾ç½®å¹¶è¡Œçº¿ç¨‹æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®ï¼Œæœ€åæ˜¯é»˜è®¤å€¼
    max_workers = threads if threads is not None else config.max_workers
    # ç¡®ä¿çº¿ç¨‹æ•°åœ¨åˆç†èŒƒå›´å†…
    max_workers = max(1, min(max_workers, 50))  # è‡³å°‘1ä¸ªçº¿ç¨‹ï¼Œæœ€å¤š50ä¸ªçº¿ç¨‹

    total_ids = len(id_list)
    print(f"å‡†å¤‡åˆ†æ {total_ids} ä¸ª{entity_type}")

    # åˆå§‹åŒ–UIç®¡ç†å™¨
    ui_manager = RichUIManager()
    ui_manager.set_multi_author_mode(total_ids)

    processed_items = []

    # å¤„ç†æ¯ä¸ªID
    for idx, item_id in enumerate(id_list, 1):
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
            cache_file = os.path.join(
                config.cache_dir, f"{'actress' if is_actress else 'author'}_{item_id}.json"
            )
            cache_valid = False

            # å¦‚æœä¹‹å‰æœ‰ç¼“å­˜ï¼Œæ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if os.path.exists(cache_file):
                try:
                    with open(cache_file, "rb") as f:
                        cache_data = json.load(f)
                    
                    # è®¡ç®—ç¼“å­˜å¹´é¾„
                    cache_time = datetime.strptime(cache_data["timestamp"], "%Y-%m-%d %H:%M:%S")
                    cache_age = (datetime.now() - cache_time).total_seconds()
                    
                    # å¦‚æœç¼“å­˜å¹´é¾„å°äºé…ç½®çš„ç¼“å­˜æœ‰æ•ˆæœŸï¼Œä½¿ç”¨ç¼“å­˜
                    if cache_age < config.cache_ttl:
                        ui_manager.add_log(
                            f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {entity_type} {item_id}", False
                        )

                        # ä½¿ç”¨ç¼“å­˜çš„ç»“æœ
                        total_videos = cache_data.get("total_videos", 0)
                        leaked_count = cache_data.get("leaked_videos", 0)
                        author_name = cache_data.get(
                            name_field, f"{entity_type}_{item_id}"
                        )

                        ui_manager.update_author_progress(idx, item_id, author_name)
                        ui_manager.mark_author_completed(
                            item_id, total_videos, leaked_count, author_name
                        )

                        processed_items.append(cache_data)
                        cache_valid = True
                        continue
                except Exception as e:
                    ui_manager.add_log(f"è¯»å–ç¼“å­˜å‡ºé”™: {e}", True)
                    # ç»§ç»­æ­£å¸¸å¤„ç†ï¼Œå¿½ç•¥ç¼“å­˜é”™è¯¯

            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç¼“å­˜ï¼Œæ­£å¸¸å¤„ç†
            if not cache_valid:
                # æ›´æ–°è¿›åº¦
                ui_manager.update_author_progress(idx, item_id)

                # åˆ›å»ºåˆ†æå™¨
                analyzer = FC2Analyzer(
                    item_id,
                    is_actress=is_actress,
                    with_magnet=with_magnet,
                    download_images=download_images,
                )

                # è·å–åç§°
                author_name = analyzer.fetch_author_name()
                if author_name:
                    ui_manager.update_author_progress(idx, item_id, author_name)

                # è·å–è§†é¢‘åˆ—è¡¨
                videos = analyzer.fetch_video_ids()
                if not videos:
                    ui_manager.add_log(f"æœªæ‰¾åˆ°{entity_type} {item_id} çš„è§†é¢‘", True)
                    ui_manager.mark_author_completed(item_id, 0, 0, author_name)
                    item_result = {
                        id_field: item_id,
                        name_field: author_name,
                        "results": [],
                        "status": "no_videos",
                    }
                    processed_items.append(item_result)
                    continue

                total_videos = len(videos)
                ui_manager.update_multi_author_total_videos(total_videos)

                # åˆ†æè§†é¢‘ï¼Œæ˜ç¡®æŒ‡å®šçº¿ç¨‹æ•°
                results, stats = analyzer.analyze_videos(videos)

                # ä¿å­˜ç»“æœ
                try:
                    analyzer.save_results()
                except Exception as e:
                    ui_manager.add_log(f"ä¿å­˜åˆ†æç»“æœæ—¶å‡ºé”™: {e}", True)
                    logger.error(f"ä¿å­˜åˆ†æç»“æœæ—¶å‡ºé”™: {type(e).__name__}: {e}")

                # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
                reports = analyzer.generate_reports(item_id, results, author_name)
                if reports:
                    print(f"âœ… æˆåŠŸä¸º{entity_type} {item_id} ç”Ÿæˆ {len(reports)} ä¸ªåˆ†ç±»æŠ¥å‘Š")
                    for report_type, report_path in reports.items():
                        print(f"  - {report_type}: {report_path}")

                # è®°å½•å¤„ç†ç»“æœ
                videos = analyzer.all_videos if hasattr(analyzer, "all_videos") else []
                results = analyzer.results if hasattr(analyzer, "results") else []

                leaked_count = sum(1 for r in results if is_leaked(r))

                # æ·»åŠ æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯åˆ°UIç®¡ç†å™¨
                if hasattr(ui_manager, "total_with_magnet"):
                    with_magnet_count = sum(
                        1
                        for r in results
                        if is_leaked(r) and r.get("has_magnet", False)
                    )
                    ui_manager.total_with_magnet = (
                        getattr(ui_manager, "total_with_magnet", 0) + with_magnet_count
                    )
                else:
                    with_magnet_count = sum(
                        1
                        for r in results
                        if is_leaked(r) and r.get("has_magnet", False)
                    )
                    ui_manager.total_with_magnet = with_magnet_count

                if hasattr(ui_manager, "total_image_downloaded"):
                    image_downloaded_count = sum(
                        1 for r in results if r.get("image_downloaded", False)
                    )
                    ui_manager.total_image_downloaded = (
                        getattr(ui_manager, "total_image_downloaded", 0)
                        + image_downloaded_count
                    )
                else:
                    image_downloaded_count = sum(
                        1 for r in results if r.get("image_downloaded", False)
                    )
                    ui_manager.total_image_downloaded = image_downloaded_count

                # æ·»åŠ é‡è¯•ç»Ÿè®¡
                if (
                    isinstance(stats, dict)
                    and "magnet_retries" in stats
                    and "magnet_retry_success" in stats
                ):
                    ui_manager.magnet_retries = getattr(
                        ui_manager, "magnet_retries", 0
                    ) + stats.get("magnet_retries", 0)
                    ui_manager.magnet_retry_success = getattr(
                        ui_manager, "magnet_retry_success", 0
                    ) + stats.get("magnet_retry_success", 0)

                ui_manager.mark_author_completed(
                    item_id, total_videos, leaked_count, author_name
                )

                item_result = {
                    id_field: item_id,
                    name_field: author_name or f"{entity_type}_{item_id}",
                    "total_videos": len(videos),
                    "processed_videos": len(results),
                    "leaked_videos": leaked_count,
                    "with_magnet": with_magnet_count,
                    "image_downloaded": image_downloaded_count,
                    "leaked_ratio": leaked_count / max(len(results), 1) * 100,
                    "results": results,
                    "status": "success",
                }

                processed_items.append(item_result)

        except Exception as e:
            ui_manager.add_log(f"å¤„ç†{entity_type} {item_id} æ—¶å‡ºé”™: {e}", True)
            ui_manager.mark_author_completed(item_id, 0, 0, None)

            item_result = {
                id_field: item_id,
                name_field: None,
                "results": [],
                "status": "error",
                "error": str(e),
            }
            processed_items.append(item_result)

    # å®Œæˆæ‰€æœ‰å¤„ç†
    ui_manager.finish()

    # åªæœ‰å½“å¤„ç†å¤šä¸ªIDæ—¶æ‰ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    if len(id_list) > 1:
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        if is_actress:
            generate_multi_actress_report(processed_items)
        else:
            generate_multi_writer_report(processed_items)
    else:
        print(f"å•{entity_type}åˆ†æå®Œæˆï¼Œæ— éœ€ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")

    # åœ¨å‡½æ•°æœ«å°¾æ·»åŠ Jellyfinå…ƒæ•°æ®ç”Ÿæˆé€»è¾‘
    if generate_jellyfin and processed_items:
        try:
            print("\n=== Jellyfinå…ƒæ•°æ® ===")
            jellyfin_generator = JellyfinMetadataGenerator()
            total_metadata_count = 0
            
            for item in processed_items:
                entity_id = item.get(id_field)
                videos_info = item.get("results", [])
                entity_name = item.get(name_field)
                
                if videos_info:
                    entity_info = {"id": entity_id, "name": entity_name} if entity_name else {"id": entity_id}
                    import asyncio
                    metadata_files = asyncio.run(jellyfin_generator.batch_generate_metadata(
                        videos_info,
                        author_info=entity_info if not is_actress else None,
                        actress_info=entity_info if is_actress else None
                    ))
                    total_metadata_count += len(metadata_files)
            
            if total_metadata_count > 0:
                print(f"âœ… {_('jellyfin.metadata_generated_batch', 'æ€»å…±ä¸º {count} ä¸ªè§†é¢‘ç”ŸæˆJellyfinå…ƒæ•°æ®').format(count=total_metadata_count)}")
                print(f"ğŸ“ {_('jellyfin.metadata_location', 'å…ƒæ•°æ®ä¿å­˜ä½ç½®: {path}').format(path=jellyfin_generator.output_dir)}")
            else:
                print(f"âš ï¸ {_('jellyfin.no_metadata_generated', 'æ²¡æœ‰æˆåŠŸç”ŸæˆJellyfinå…ƒæ•°æ®')}")
        except Exception as e:
            logger.error(f"æ‰¹é‡ç”ŸæˆJellyfinå…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            print(f"âŒ {_('jellyfin.metadata_error_batch', 'æ‰¹é‡ç”ŸæˆJellyfinå…ƒæ•°æ®æ—¶å‡ºé”™: {error}').format(error=str(e))}")

    return True


def generate_multi_writer_report(processed_writers):
    """ç”Ÿæˆå¤šä½œè€…æ±‡æ€»æŠ¥å‘Š

    å°†å¤šä¸ªä½œè€…çš„åˆ†æç»“æœæ±‡æ€»åˆ°ä¸€ä¸ªæŠ¥å‘Šä¸­

    å‚æ•°:
        processed_writers: å¤„ç†è¿‡çš„ä½œè€…åˆ—è¡¨
    """
    if not processed_writers:
        print("æ²¡æœ‰æ•°æ®å¯ä»¥ç”ŸæˆæŠ¥å‘Š")
        return

    # ä½¿ç”¨ReportGeneratorç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    report_generator = ReportGenerator()
    report_path = report_generator.generate_multi_writer_report(processed_writers)

    if report_path:
        print(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    else:
        print("âŒ æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå¤±è´¥")


def generate_multi_actress_report(processed_actresses):
    """ç”Ÿæˆå¤šå¥³ä¼˜æ±‡æ€»æŠ¥å‘Š

    å°†å¤šä¸ªå¥³ä¼˜çš„åˆ†æç»“æœæ±‡æ€»åˆ°ä¸€ä¸ªæŠ¥å‘Šä¸­

    å‚æ•°:
        processed_actresses: å¤„ç†è¿‡çš„å¥³ä¼˜åˆ—è¡¨
    """
    if not processed_actresses:
        print("æ²¡æœ‰æ•°æ®å¯ä»¥ç”ŸæˆæŠ¥å‘Š")
        return

    # ä½¿ç”¨ReportGeneratorç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    report_generator = ReportGenerator()
    report_path = report_generator.generate_multi_actress_report(processed_actresses)

    if report_path:
        print(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    else:
        print("âŒ æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå¤±è´¥")


def find_writer_by_video_id(
    video_id, threads=None, with_magnet=True, download_images=True, generate_jellyfin=False
):
    """é€šè¿‡è§†é¢‘IDæŸ¥æ‰¾å¹¶åˆ†æä½œè€…

    é€šè¿‡åœ¨FC2PPVDBä¸ŠæŸ¥è¯¢è§†é¢‘ä¿¡æ¯ï¼Œè·å–ä½œè€…ä¿¡æ¯å¹¶åˆ†æå…¶æ‰€æœ‰ä½œå“

    Args:
        video_id: è§†é¢‘ID
        threads: å¹¶è¡Œçº¿ç¨‹æ•°
        with_magnet: æ˜¯å¦è·å–ç£åŠ›é“¾æ¥
        download_images: æ˜¯å¦ä¸‹è½½ç¼©ç•¥å›¾
        generate_jellyfin: æ˜¯å¦ç”ŸæˆJellyfinå…ƒæ•°æ®

    Returns:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    print(_("find_writer.start", "å¼€å§‹é€šè¿‡è§†é¢‘ID {id} æŸ¥æ‰¾ä½œè€…ä¿¡æ¯...").format(id=video_id))

    try:
        # è®¾ç½®è¯·æ±‚è¶…æ—¶
        timeout = config.timeout  # ä»é…ç½®è·å–è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤15ç§’

        # ä½¿ç”¨fc2_video_parseræŸ¥æ‰¾ä½œè€…
        writer_id, writer_username = find_writer_by_video(video_id)

        if not writer_id:
            if writer_username:
                print(_("find_writer.found_username_no_id", "å·²æ‰¾åˆ°ä½œè€…ç”¨æˆ·å {username}ï¼Œä½†æ— æ³•è·å–å…¶ID").format(username=writer_username))
            else:
                print(_("find_writer.not_found", "æ— æ³•é€šè¿‡è§†é¢‘ID {id} æ‰¾åˆ°ä½œè€…ä¿¡æ¯").format(id=video_id))
            return False

        print(_("find_writer.found", "å·²æ‰¾åˆ°ä½œè€…: ID={id}, ç”¨æˆ·å={username}").format(id=writer_id, username=writer_username))
        print(_("find_writer.analyze_start", "å¼€å§‹åˆ†æä½œè€… {id} çš„æ‰€æœ‰è§†é¢‘...").format(id=writer_id))

        # ä½¿ç”¨æ‰¾åˆ°çš„ä½œè€…IDè¿›è¡Œåˆ†æ
        return check_videos(
            writer_id,
            is_actress=False,
            threads=threads,
            with_magnet=with_magnet,
            download_images=download_images,
            generate_jellyfin=generate_jellyfin
        )
    except ConnectionError as e:
        logger.error(f"æŸ¥æ‰¾ä½œè€…æ—¶è¿æ¥é”™è¯¯: {e}")
        print(_("find_writer.error_connection", "æŸ¥æ‰¾ä½œè€…æ—¶è¿æ¥é”™è¯¯: {error}").format(error=e))
        return False
    except Timeout as e:
        logger.error(f"æŸ¥æ‰¾ä½œè€…æ—¶è¿æ¥è¶…æ—¶: {e}")
        print(_("find_writer.error_timeout", "æŸ¥æ‰¾ä½œè€…æ—¶è¿æ¥è¶…æ—¶: {error}").format(error=e))
        return False
    except JSONDecodeError as e:
        logger.error(f"è§£æä½œè€…æ•°æ®æ—¶æ ¼å¼é”™è¯¯: {e}")
        print(_("find_writer.error_json", "è§£æä½œè€…æ•°æ®æ—¶æ ¼å¼é”™è¯¯: {error}").format(error=e))
        return False
    except ValueError as e:
        logger.error(f"æŸ¥æ‰¾ä½œè€…å‚æ•°é”™è¯¯: {e}")
        print(_("find_writer.error_value", "æŸ¥æ‰¾ä½œè€…å‚æ•°é”™è¯¯: {error}").format(error=e))
        return False
    except Exception as e:
        logger.error(f"æŸ¥æ‰¾ä½œè€…æ—¶æœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}\n{traceback.format_exc()}")
        print(_("find_writer.error_unknown", "æŸ¥æ‰¾ä½œè€…æ—¶å‡ºé”™: {error}").format(error=f"{type(e).__name__}: {e}"))
        return False


def generate_jellyfin_only():
    """
    ç‹¬ç«‹æ‰§è¡ŒJellyfinå…ƒæ•°æ®ç”Ÿæˆï¼ŒåŸºäºå·²æœ‰çš„ç¼“å­˜ç»“æœæ–‡ä»¶
    
    åœ¨æ²¡æœ‰æŒ‡å®š-a/-w/-b/-ba/-vå‚æ•°çš„æƒ…å†µä¸‹ï¼Œä½†æŒ‡å®šäº†--jellyfinå‚æ•°æ—¶æ‰§è¡Œæ­¤å‡½æ•°
    æŸ¥æ‰¾æœ€è¿‘48å°æ—¶å†…çš„åˆ†æç»“æœæ–‡ä»¶ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦åŸºäºè¯¥ç»“æœç”Ÿæˆå…ƒæ•°æ®
    
    Returns:
        bool: æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    try:
        # è·å–å½“å‰æ—¶é—´
        now = datetime.now()
        # è®¡ç®—48å°æ—¶å‰çš„æ—¶é—´æˆ³
        cache_threshold = now - timedelta(seconds=config.cache_ttl)
        
        # æŸ¥æ‰¾resultsç›®å½•ä¸­çš„æ‰€æœ‰æ€»æŠ¥å‘Šæ–‡ä»¶
        report_files = glob.glob(os.path.join(config.result_dir, "*_æ€»æŠ¥å‘Š.txt"))
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æŠ¥å‘Šæ–‡ä»¶
        if not report_files:
            print(f"âŒ {_('jellyfin_only.no_reports', 'æœªæ‰¾åˆ°ä»»ä½•åˆ†æç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨-a/-w/-b/-ba/-vå‚æ•°è¿›è¡Œåˆ†æ')}")
            return False
            
        # æŒ‰æœ€åä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
        report_files.sort(key=os.path.getmtime, reverse=True)
        
        # æŸ¥æ‰¾48å°æ—¶å†…çš„æŠ¥å‘Šæ–‡ä»¶
        valid_reports = []
        for report_file in report_files:
            # è·å–æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´
            file_mtime = datetime.fromtimestamp(os.path.getmtime(report_file))
            
            # å¦‚æœæ–‡ä»¶åœ¨48å°æ—¶å†…ä¿®æ”¹è¿‡
            if file_mtime >= cache_threshold:
                # æ–‡ä»¶åæ¨¡å¼ï¼šid_name_æ€»æŠ¥å‘Š.txt
                filename = os.path.basename(report_file)
                
                # æå–entity_idå’Œentity_name
                report_data = {'file_path': report_file, 'mtime': file_mtime}
                
                # è¯»å–æ–‡ä»¶å†…å®¹æå–ä¿¡æ¯
                with open(report_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    
                    # è§£æç¬¬ä¸€è¡Œè·å–ç±»å‹å’ŒID
                    if lines and len(lines) > 0:
                        first_line = lines[0].strip()
                        # æ ¼å¼ï¼š"ä½œè€…ID: 1476" æˆ– "å¥³ä¼˜ID: 5711"
                        id_match = re.match(r'(ä½œè€…|å¥³ä¼˜)ID: (\d+)', first_line)
                        if id_match:
                            report_data['entity_type'] = id_match.group(1)  # ä½œè€… æˆ– å¥³ä¼˜
                            report_data['entity_id'] = id_match.group(2)
                    
                    # è§£æç¬¬äºŒè¡Œè·å–åç§°
                    if len(lines) > 1:
                        second_line = lines[1].strip()
                        # æ ¼å¼ï¼š"ä½œè€…åç§°: ã±ã™ã‚‚" æˆ– "å¥³ä¼˜åç§°: ã¿ãŠ å¥³å„ª"
                        name_match = re.match(r'(ä½œè€…|å¥³ä¼˜)åç§°: (.+?)(?:åˆ†ææ—¶é—´:|$)', second_line)
                        if name_match:
                            report_data['entity_name'] = name_match.group(2).strip()
                    
                    # æ£€æŸ¥åˆ†ææ—¶é—´
                    time_match = None
                    for line in lines[:3]:  # åªæ£€æŸ¥å‰å‡ è¡Œ
                        if 'åˆ†ææ—¶é—´:' in line:
                            time_match = re.search(r'åˆ†ææ—¶é—´: (\d{8}_\d{6})', line)
                            if time_match:
                                report_data['timestamp'] = time_match.group(1)
                                break
                
                # å¦‚æœæˆåŠŸæå–åˆ°IDå’Œç±»å‹ï¼Œåˆ™æ·»åŠ åˆ°æœ‰æ•ˆæŠ¥å‘Šåˆ—è¡¨
                if 'entity_id' in report_data and 'entity_type' in report_data:
                    valid_reports.append(report_data)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æŠ¥å‘Šæ–‡ä»¶
        if not valid_reports:
            print(f"âŒ {_('jellyfin_only.no_recent_reports', 'æœªæ‰¾åˆ°48å°æ—¶å†…çš„åˆ†æç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆä½¿ç”¨-a/-w/-b/-ba/-vå‚æ•°è¿›è¡Œåˆ†æ')}")
            return False
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æŠ¥å‘Šæ–‡ä»¶åˆ—è¡¨
        print(f"\n{_('jellyfin_only.found_reports', 'æ‰¾åˆ°ä»¥ä¸‹{count}ä¸ª48å°æ—¶å†…çš„åˆ†æç»“æœ:').format(count=len(valid_reports))}")
        for i, report in enumerate(valid_reports, 1):
            entity_type = _('analyzer.entity_type_actress', 'å¥³ä¼˜') if report['entity_type'] == 'å¥³ä¼˜' else _('analyzer.entity_type_writer', 'ä½œè€…')
            entity_id = report['entity_id']
            entity_name = report.get('entity_name', _('jellyfin_only.unknown_name', 'æœªçŸ¥'))
            file_time = report['mtime'].strftime('%Y-%m-%d %H:%M:%S')
            
            print(f"{i}. {entity_type}ID: {entity_id}, {_('jellyfin_only.entity_name', 'åç§°')}: {entity_name}, {_('jellyfin_only.analysis_time', 'åˆ†ææ—¶é—´')}: {file_time}")
        
        # è¯¢é—®ç”¨æˆ·é€‰æ‹©ä½¿ç”¨å“ªä¸ªæŠ¥å‘Šæ–‡ä»¶
        choice = input(f"\n{_('jellyfin_only.select_report', 'è¯·è¾“å…¥è¦ä½¿ç”¨çš„æŠ¥å‘Šåºå·(ç›´æ¥å›è½¦å–æ¶ˆ)')}: ")
        if not choice.strip():
            print(_('jellyfin_only.operation_cancelled', 'å·²å–æ¶ˆæ“ä½œ'))
            return False
        
        try:
            choice_idx = int(choice) - 1
            if choice_idx < 0 or choice_idx >= len(valid_reports):
                print(f"âŒ {_('jellyfin_only.invalid_number', 'æ— æ•ˆçš„åºå·')}")
                return False
                
            selected_report = valid_reports[choice_idx]
            entity_type_display = _('analyzer.entity_type_actress', 'å¥³ä¼˜') if selected_report['entity_type'] == 'å¥³ä¼˜' else _('analyzer.entity_type_writer', 'ä½œè€…')
            print(f"\n{_('jellyfin_only.selected_report', 'å·²é€‰æ‹©')}: {entity_type_display}ID: {selected_report['entity_id']}, {_('jellyfin_only.entity_name', 'åç§°')}: {selected_report.get('entity_name', _('jellyfin_only.unknown_name', 'æœªçŸ¥'))}")
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤
            confirm = input(f"{_('jellyfin_only.confirm_selection', 'æ˜¯å¦ç¡®è®¤ä½¿ç”¨æ­¤æŠ¥å‘Šç”ŸæˆJellyfinå…ƒæ•°æ®? (y/n)')}: ")
            if confirm.lower() != 'y':
                print(_('jellyfin_only.operation_cancelled', 'å·²å–æ¶ˆæ“ä½œ'))
                return False
            
            # æ ¹æ®ç±»å‹ç¡®å®šæ˜¯ä½œè€…è¿˜æ˜¯å¥³ä¼˜
            is_actress = selected_report['entity_type'] == 'å¥³ä¼˜'
            entity_id = selected_report['entity_id']
            entity_name = selected_report.get('entity_name', '')
            
            # åˆ›å»ºå®ä½“ä¿¡æ¯å¯¹è±¡
            entity_info = {
                "id": entity_id,
                "name": entity_name
            }
            
            # å°è¯•è¯»å–ç¼“å­˜æ•°æ®
            cache_file = os.path.join(
                config.cache_dir, f"{'actress' if is_actress else 'author'}_{entity_id}.json"
            )
            
            videos_info = []
            used_cache = False
            
            # å¦‚æœç¼“å­˜æ–‡ä»¶å­˜åœ¨
            if os.path.exists(cache_file):
                try:
                    with open(cache_file, "r", encoding="utf-8") as f:
                        cache_data = json.load(f)
                    
                    # æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæœŸ
                    cache_time = datetime.strptime(cache_data["timestamp"], "%Y-%m-%d %H:%M:%S")
                    cache_age = (datetime.now() - cache_time).total_seconds()
                    
                    if cache_age < config.cache_ttl:
                        videos_info = cache_data.get("results", [])
                        
                        # æ£€æŸ¥ç¼“å­˜ä¸­çš„è§†é¢‘ä¿¡æ¯æ˜¯å¦æœ‰æ•ˆ
                        if videos_info and isinstance(videos_info, list) and all("video_id" in v for v in videos_info):
                            print(f"ğŸ”„ {_('jellyfin_only.using_cache', 'ä½¿ç”¨ç¼“å­˜æ•°æ®')}")
                            used_cache = True
                        else:
                            print(f"âš ï¸ {_('jellyfin_only.invalid_cache', 'ç¼“å­˜æ•°æ®æ— æ•ˆæˆ–ä¸å®Œæ•´')}")
                            videos_info = []
                    else:
                        print(f"âš ï¸ {_('jellyfin_only.cache_expired', 'ç¼“å­˜æ•°æ®å·²è¿‡æœŸ')}")
                except Exception as e:
                    logger.error(f"è¯»å–ç¼“å­˜å‡ºé”™: {e}")
                    print(f"âš ï¸ {_('jellyfin_only.cache_error', 'è¯»å–ç¼“å­˜å‡ºé”™')}: {e}")
                    videos_info = []
            
            # å¦‚æœæ²¡æœ‰ä»ç¼“å­˜è·å–åˆ°æœ‰æ•ˆçš„è§†é¢‘ä¿¡æ¯ï¼Œåˆ™ä»æŠ¥å‘Šæ–‡ä»¶è§£æ
            if not videos_info:
                print(f"ğŸ” {_('jellyfin_only.parsing_report', 'ä»æŠ¥å‘Šæ–‡ä»¶è§£æè§†é¢‘ä¿¡æ¯...')}")
                
                # è¯»å–æŠ¥å‘Šæ–‡ä»¶å¹¶è§£æå·²æµå‡ºè§†é¢‘åˆ—è¡¨
                try:
                    with open(selected_report['file_path'], 'r', encoding='utf-8') as f:
                        report_content = f.read()
                    
                    # æŸ¥æ‰¾å·²æµå‡ºè§†é¢‘åˆ—è¡¨éƒ¨åˆ†
                    leaked_section_match = re.search(r'===\s*å·²æµå‡ºè§†é¢‘åˆ—è¡¨\s*===\s*(.*?)(?:===\s*æœªæµå‡ºè§†é¢‘åˆ—è¡¨\s*===|\Z)', report_content, re.DOTALL)
                    
                    if leaked_section_match:
                        leaked_section = leaked_section_match.group(1).strip()
                        
                        # å°è¯•ä¸åŒçš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è§†é¢‘æ¡ç›®
                        video_entries = re.findall(r'(\d+).\s*\[(\d+)\].*?(\[æœ‰ç£é“¾\]|\[æ— ç£é“¾\])?\s*(.*?)(?=\d+\.\s*\[|\Z)', leaked_section, re.DOTALL)
                        
                        # å¦‚æœä¸Šé¢çš„æ­£åˆ™è¡¨è¾¾å¼æ²¡æœ‰åŒ¹é…åˆ°ï¼Œå°è¯•å¦ä¸€ç§æ ¼å¼
                        if not video_entries:
                            video_entries = re.findall(r'(\d+).\s*\[(\d+)\](.*)', leaked_section.split('\n'))
                            
                        # å¤„ç†åŒ¹é…åˆ°çš„è§†é¢‘æ¡ç›®
                        for entry in video_entries:
                            if len(entry) == 4:  # ç¬¬ä¸€ç§æ­£åˆ™è¡¨è¾¾å¼
                                video_id = entry[1]
                                title_part = entry[3]
                            elif len(entry) == 3:  # ç¬¬äºŒç§æ­£åˆ™è¡¨è¾¾å¼
                                video_id = entry[1]
                                title_part = entry[2]
                            else:
                                continue
                                
                            # æå–è§†é¢‘æ ‡é¢˜ (ç§»é™¤å‰é¢çš„[æœ‰ç£é“¾]/[æ— ç£é“¾]éƒ¨åˆ†)
                            title_match = re.search(r'(?:\[æœ‰ç£é“¾\]|\[æ— ç£é“¾\])?\s*(.*)', title_part)
                            title = title_match.group(1).strip() if title_match else f"FC2-PPV-{video_id}"
                            
                            # åˆ›å»ºè§†é¢‘ä¿¡æ¯å¯¹è±¡
                            video_info = {
                                "video_id": video_id,
                                "title": title,
                                "status": "available",
                                "leaked": True
                            }
                            
                            videos_info.append(video_info)
                except Exception as e:
                    logger.error(f"è§£ææŠ¥å‘Šæ–‡ä»¶å‡ºé”™: {e}")
                    print(f"âŒ {_('jellyfin_only.parse_error', 'è§£ææŠ¥å‘Šæ–‡ä»¶å‡ºé”™')}: {e}")
                    traceback.print_exc()  # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆè·Ÿè¸ª
                    
                    # å¦‚æœæŠ¥å‘Šæ–‡ä»¶è§£æå¤±è´¥ï¼Œå°è¯•è¯»å–å·²æµå‡ºè§†é¢‘æ€»è¡¨æ–‡ä»¶
                    try:
                        leaked_summary_file = selected_report['file_path'].replace('_æ€»æŠ¥å‘Š.txt', '_å·²æµå‡ºè§†é¢‘æ€»è¡¨.txt')
                        
                        if os.path.exists(leaked_summary_file):
                            print(f"ğŸ” {_('jellyfin_only.parsing_summary', 'å°è¯•ä»å·²æµå‡ºè§†é¢‘æ€»è¡¨æ–‡ä»¶è§£æ...')}")
                            
                            with open(leaked_summary_file, 'r', encoding='utf-8') as f:
                                lines = f.readlines()
                                
                                for line in lines:
                                    # æ ¼å¼: FC2-PPV-1234567 | è§†é¢‘æ ‡é¢˜
                                    match = re.match(r'FC2-PPV-(\d+) \| (.+)', line.strip())
                                    if match:
                                        video_id = match.group(1)
                                        title = match.group(2)
                                        
                                        video_info = {
                                            "video_id": video_id,
                                            "title": title,
                                            "status": "available",
                                            "leaked": True
                                        }
                                        
                                        videos_info.append(video_info)
                        else:
                            print(f"âŒ {_('jellyfin_only.summary_not_found', 'æœªæ‰¾åˆ°å·²æµå‡ºè§†é¢‘æ€»è¡¨æ–‡ä»¶')}")
                    except Exception as e2:
                        logger.error(f"è§£æå·²æµå‡ºè§†é¢‘æ€»è¡¨æ–‡ä»¶å‡ºé”™: {e2}")
                        print(f"âŒ {_('jellyfin_only.summary_parse_error', 'è§£æå·²æµå‡ºè§†é¢‘æ€»è¡¨æ–‡ä»¶å‡ºé”™')}: {e2}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘ä¿¡æ¯
            if not videos_info:
                print(f"âŒ {_('jellyfin_only.no_videos_found', 'æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘ä¿¡æ¯')}")
                return False
            
            # ç­›é€‰å·²æµå‡ºçš„è§†é¢‘
            leaked_videos = [v for v in videos_info if v.get("status") == "available" or v.get("leaked") == True]
            
            if not leaked_videos:
                print(f"âŒ {_('jellyfin.no_leaked_videos', 'æ²¡æœ‰å·²æµå‡ºçš„è§†é¢‘ï¼Œè·³è¿‡ç”ŸæˆJellyfinå…ƒæ•°æ®')}")
                return False
            
            print(f"âœ… {_('jellyfin_only.found_videos', 'æ‰¾åˆ° {count} ä¸ªè§†é¢‘ï¼Œå…¶ä¸­ {leaked} ä¸ªå·²æµå‡º').format(count=len(videos_info), leaked=len(leaked_videos))}")
            
            # ç”ŸæˆJellyfinå…ƒæ•°æ®
            print(f"\n=== {_('jellyfin_only.jellyfin_metadata', 'Jellyfinå…ƒæ•°æ®')} ===")
            jellyfin_generator = JellyfinMetadataGenerator()
            
            # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥æ–¹æ³•
            import asyncio
            metadata_results = asyncio.run(jellyfin_generator.batch_generate_metadata(
                leaked_videos,
                author_info=entity_info if not is_actress else None,
                actress_info=entity_info if is_actress else None,
                enrich_from_web=True  # å§‹ç»ˆä»ç½‘ç»œè·å–é¢å¤–ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡ç­¾
            ))
            
            if metadata_results:
                print(f"âœ… {_('jellyfin_only.generation_success', 'æˆåŠŸç”Ÿæˆ {count} ä¸ªJellyfinå…ƒæ•°æ®æ–‡ä»¶').format(count=len(metadata_results))}")
                print(f"ğŸ“ {_('jellyfin.metadata_location', 'å…ƒæ•°æ®ä¿å­˜ä½ç½®: {path}').format(path=jellyfin_generator.output_dir)}")
                return True
            else:
                print(f"âŒ {_('jellyfin_only.generation_failed', 'æœªç”Ÿæˆä»»ä½•Jellyfinå…ƒæ•°æ®æ–‡ä»¶')}")
                return False
                
        except ValueError:
            print(f"âŒ {_('jellyfin_only.invalid_input', 'æ— æ•ˆçš„è¾“å…¥')}")
            return False
            
    except Exception as e:
        logger.error(f"ç”ŸæˆJellyfinå…ƒæ•°æ®æ—¶å‡ºé”™: {str(e)}\n{traceback.format_exc()}")
        print(f"âŒ {_('jellyfin_only.error', 'ç”ŸæˆJellyfinå…ƒæ•°æ®æ—¶å‡ºé”™')}: {str(e)}")
        return False


def main():
    """ç¨‹åºä¸»å…¥å£"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description=_("app_description", "FC2æµå‡ºæ£€æµ‹å™¨"), add_help=False)
    parser.add_argument("-h", "--help", action="store_true", help=_("usage_help", "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"))
    parser.add_argument("-w", "--writer", type=str, help=_("usage_writer", "åˆ†æä½œè€…IDçš„è§†é¢‘"))
    parser.add_argument("-a", "--actress", type=str, help=_("usage_actress", "åˆ†æå¥³ä¼˜IDçš„è§†é¢‘"))
    parser.add_argument("-b", "--batch", type=str, help=_("usage_batch", "æ‰¹é‡å¤„ç†å¤šä¸ªä½œè€…IDï¼ˆç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼‰"))
    parser.add_argument("-ba", "--batch-actress", type=str, help=_("usage_batch_actress", "æ‰¹é‡å¤„ç†å¤šä¸ªå¥³ä¼˜IDï¼ˆç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼‰"))
    parser.add_argument("-v", "--video", type=str, help=_("usage_video", "é€šè¿‡è§†é¢‘IDæŸ¥æ‰¾å¹¶åˆ†æä½œè€…"))
    parser.add_argument("-t", "--threads", type=int, help=_("usage_threads", "æŒ‡å®šå¹¶è¡Œçº¿ç¨‹æ•°"))
    parser.add_argument("--jellyfin", action="store_true", help=_("usage_jellyfin", "ç”ŸæˆJellyfinå…¼å®¹çš„å…ƒæ•°æ®ï¼›å¯å•ç‹¬ä½¿ç”¨ï¼Œä¼šæŸ¥æ‰¾48å°æ—¶å†…çš„åˆ†æç»“æœ"))
    parser.add_argument("--no-magnet", action="store_true", help=_("usage_no_magnet", "ä¸è·å–ç£åŠ›é“¾æ¥"))
    parser.add_argument("--no-image", action="store_true", help=_("usage_no_image", "ä¸ä¸‹è½½è§†é¢‘ç¼©ç•¥å›¾"))
    parser.add_argument("-l", "--lang", type=str, help=_("usage_lang", "è®¾ç½®ç•Œé¢è¯­è¨€ (æ”¯æŒ: zh, en, ja)"))
    parser.add_argument("-c", "--config", action="store_true", help=_("usage_config", "æ˜¾ç¤ºé…ç½®ä¿¡æ¯"))
    parser.add_argument("-s", "--sites", action="store_true", help=_("usage_sites", "æ˜¾ç¤ºæ£€æŸ¥ç«™ç‚¹åˆ—è¡¨"))
    parser.add_argument("-e", "--extract", action="store_true", help=_("usage_extract", "æå–çƒ­é—¨ä½œè€…åˆ—è¡¨"))
    parser.add_argument("--clear-cache", action="store_true", help=_("usage_clear_cache", "æ¸…é™¤æ‰€æœ‰ç¼“å­˜æ•°æ®"))

    try:
        args = parser.parse_args()

        # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if args.help:
            print_usage()
            return 0

        # è®¾ç½®è¯­è¨€
        if args.lang:
            if args.lang in SUPPORTED_LANGUAGES:
                switch_language(args.lang)
                print(f"ğŸŒ {_('main.language_switched', 'å·²åˆ‡æ¢è¯­è¨€ä¸º: {lang}').format(lang=args.lang)}")
            else:
                print(f"âŒ {_('main.unsupported_language', 'ä¸æ”¯æŒçš„è¯­è¨€: {lang}').format(lang=args.lang)}")
                return 1

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        if args.config:
            display_config()
            return 0

        # æ˜¾ç¤ºæ£€æŸ¥ç«™ç‚¹åˆ—è¡¨
        if args.sites:
            display_sites()
            return 0

        # æ¸…é™¤ç¼“å­˜
        if args.clear_cache:
            clear_cache()
            return 0

        # è®¾ç½®çº¿ç¨‹æ•°
        threads = args.threads if args.threads else config.max_workers

        # æå–çƒ­é—¨ä½œè€…åˆ—è¡¨
        if args.extract:
            success = extract_writer_info()
            return 0 if success else 1

        # è®¾ç½®ç£é“¾å’Œå›¾ç‰‡ä¸‹è½½é€‰é¡¹
        with_magnet = not args.no_magnet
        download_images = not args.no_image
        generate_jellyfin = args.jellyfin

        # é€šè¿‡è§†é¢‘IDæŸ¥æ‰¾å¹¶åˆ†æä½œè€…
        if args.video:
            success = find_writer_by_video_id(
                args.video, threads, with_magnet, download_images, generate_jellyfin
            )
            return 0 if success else 1

        # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ‰§è¡Œç›¸åº”åŠŸèƒ½
        if args.writer:
            check_videos(
                args.writer,
                is_actress=False,
                threads=threads,
                with_magnet=with_magnet,
                download_images=download_images,
                generate_jellyfin=generate_jellyfin
            )
        elif args.actress:
            check_videos(
                args.actress,
                is_actress=True,
                threads=threads,
                with_magnet=with_magnet,
                download_images=download_images,
                generate_jellyfin=generate_jellyfin
            )
        elif args.batch:
            process_multiple_ids(
                args.batch,
                is_actress=False,
                threads=threads,
                with_magnet=with_magnet,
                download_images=download_images,
                generate_jellyfin=generate_jellyfin
            )
        elif args.batch_actress:
            process_multiple_ids(
                args.batch_actress,
                is_actress=True,
                threads=threads,
                with_magnet=with_magnet,
                download_images=download_images,
                generate_jellyfin=generate_jellyfin
            )
        # æ·»åŠ åªæœ‰--jellyfinå‚æ•°çš„æƒ…å†µ
        elif generate_jellyfin:
            # ç›´æ¥è°ƒç”¨ç‹¬ç«‹çš„Jellyfinå…ƒæ•°æ®ç”Ÿæˆå‡½æ•°
            generate_jellyfin_only()
        else:
            print_usage()

        return 0

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­äº†æ“ä½œ")
        return 130  # æ ‡å‡†Unixä¸­æ–­é€€å‡ºç 
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}\n{traceback.format_exc()}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
